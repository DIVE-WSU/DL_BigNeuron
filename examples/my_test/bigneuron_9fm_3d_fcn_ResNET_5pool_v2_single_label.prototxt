layer {
  name: "data"
  type: "PatchData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  patch_sampler_param{
	   data_patch_shape{
		dim: 224
		dim: 224
		dim: 8
	   }
	   label_patch_shape{
		dim: 1
		dim: 1
		dim: 1
	   }
	   batch_size: 16
	   patches_per_data_batch: 899999
	   #data_source_batch_size: 1

 }

label_select_param{
	balance: true
	num_labels: 3
	num_top_label_balance: 2
	reorder_label: false
	class_prob_mapping_file: 'label_class_selection.prototxt'
}
  transform_nd_param{
    mirror: false
    padding: true
    pad_method: ZERO
    mean_value: 113
  }
  data_provider_param{
    # Specify the data source.
    backend: HDF5
    batch_size: 1
    hdf5_file_shuffle: true
    data_source: "hdf5_train_file_list.txt"
  }

}


layer {
  name: "data"
  type: "PatchData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  patch_sampler_param{
	   data_patch_shape{
		dim: 224
		dim: 224
		dim: 8
	   }
	   label_patch_shape{
		dim: 1
		dim: 1
		dim: 1
	   }
	   batch_size: 4
	   patches_per_data_batch: 899999
	   #data_source_batch_size: 1
 }

 label_select_param{
			   balance: true
			   num_labels: 3
			   num_top_label_balance: 2
			   reorder_label: false
			   class_prob_mapping_file: 'label_class_selection_valid.prototxt'
		}
  transform_nd_param{
    mirror: false
    padding: true
    pad_method: ZERO
    mean_value: 113
  }
  data_provider_param{
    # Specify the data source.
    backend: HDF5
    batch_size: 1
    hdf5_file_shuffle: true
    data_source: "hdf5_test_file_list.txt"
  }

}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
	kernel_size: 7
	kernel_size: 4
    stride: 2
	pad:3
	pad:3
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape: 3
	kernel_shape: 3
	kernel_shape: 3
    stride_shape: 2
	stride_shape: 2
	stride_shape: 1
  }
}



#------------------------------------------- conv2x-------------------------------------
#---------------con2x_top-------------

layer {
  name: "conv2x_top"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2x_top"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

#---------------------------  block layers conv2_1 ----------------------------

layer {
  name: "conv2x_1_1"
  type: "Convolution"
  bottom: "conv2x_top"
  top: "conv2x_1_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_1_1"
  type: "ReLU"
  bottom: "conv2x_1_1"
  top: "conv2x_1_1"
}
layer {
  name: "conv2x_1_2"
  type: "Convolution"
  bottom: "conv2x_1_1"
  top: "conv2x_1_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_1_2"
  type: "ReLU"
  bottom: "conv2x_1_2"


  top: "conv2x_1_2"
}

layer {
  name: "conv2x_1_3"
  type: "Convolution"
  bottom: "conv2x_1_2"
  top: "conv2x_1_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv2x_1_sum"
type:  "Eltwise"
bottom:"conv2x_top"
bottom:"conv2x_1_3"
top:"conv2x_1_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu2x_1_sum"
  type: "ReLU"
  bottom: "conv2x_1_sum"
  top: "conv2x_1_sum"
}



#------------ block layers conv2_2--------------------

layer {
  name: "conv2x_2_1"
  type: "Convolution"
  bottom: "conv2x_1_sum"
  top: "conv2x_2_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_2_1"
  type: "ReLU"
  bottom: "conv2x_2_1"
  top: "conv2x_2_1"
}
layer {
  name: "conv2x_2_2"
  type: "Convolution"
  bottom: "conv2x_2_1"
  top: "conv2x_2_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_2_2"
  type: "ReLU"
  bottom: "conv2x_2_2"
  top: "conv2x_2_2"
}
layer {
  name: "conv2x_2_3"
  type: "Convolution"
  bottom: "conv2x_2_2"
  top: "conv2x_2_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv2x_2_sum"
type:  "Eltwise"
bottom:"conv2x_1_sum"
bottom:"conv2x_2_3"
top:"conv2x_2_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu2x_2_sum"
  type: "ReLU"
  bottom: "conv2x_2_sum"
  top: "conv2x_2_sum"
}
#------------ block layers conv2_3--------------------
layer {
  name: "conv2x_3_1"
  type: "Convolution"
  bottom: "conv2x_2_sum"
  top: "conv2x_3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_3_1"
  type: "ReLU"
  bottom: "conv2x_3_1"
  top: "conv2x_3_1"
}
layer {
  name: "conv2x_3_2"
  type: "Convolution"
  bottom: "conv2x_3_1"
  top: "conv2x_3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_3_2"
  type: "ReLU"
  bottom: "conv2x_3_2"
  top: "conv2x_3_2"
}
layer {
  name: "conv2x_3_3"
  type: "Convolution"
  bottom: "conv2x_3_2"
  top: "conv2x_3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv2x_3_sum"
type:  "Eltwise"
bottom:"conv2x_2_sum"
bottom:"conv2x_3_3"
top:"conv2x_3_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu2x_3_sum"
  type: "ReLU"
  bottom: "conv2x_3_sum"
  top: "conv2x_3_sum"
  }

#------------ block layers conv2_3--------------------


#------------------- conv3_x_-----------------------
layer {
  name: "conv3x_top"
  type: "Convolution"
  bottom: "conv2x_3_sum"
  top: "conv3x_top"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	stride :2
	stride :2
	stride :1
	pad :1
	pad :1
	pad :0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

#------------ block layers conv3_1--------------------
layer {
  name: "conv3x_1_1"
  type: "Convolution"
  bottom: "conv3x_top"
  top: "conv3x_1_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_1_1"
  type: "ReLU"
  bottom: "conv3x_1_1"
  top: "conv3x_1_1"
}
layer {
  name: "conv3x_1_2"
  type: "Convolution"
  bottom: "conv3x_1_1"
  top: "conv3x_1_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_1_2"
  type: "ReLU"
  bottom: "conv3x_1_2"
  top: "conv3x_1_2"
}
layer {
  name: "conv3x_1_3"
  type: "Convolution"
  bottom: "conv3x_1_2"
  top: "conv3x_1_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv3x_1_sum"
type:  "Eltwise"
bottom:"conv3x_top"
bottom:"conv3x_1_3"
top:"conv3x_1_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu3x_1_sum"
  type: "ReLU"
  bottom: "conv3x_1_sum"
  top: "conv3x_1_sum"
  }
#------------ block layers conv3_2--------------------


layer {
  name: "conv3x_2_1"
  type: "Convolution"
  bottom: "conv3x_1_sum"
  top: "conv3x_2_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_2_1"
  type: "ReLU"
  bottom: "conv3x_2_1"
  top: "conv3x_2_1"
}
layer {
  name: "conv3x_2_2"
  type: "Convolution"
  bottom: "conv3x_2_1"
  top: "conv3x_2_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_2_2"
  type: "ReLU"
  bottom: "conv3x_2_2"
  top: "conv3x_2_2"
}
layer {
  name: "conv3x_2_3"
  type: "Convolution"
  bottom: "conv3x_2_2"
  top: "conv3x_2_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv3x_2_sum"
type:  "Eltwise"
bottom:"conv3x_1_sum"
bottom:"conv3x_2_3"
top:"conv3x_2_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu3x_2_sum"
  type: "ReLU"
  bottom: "conv3x_2_sum"
  top: "conv3x_2_sum"
  }

#------------ block layers conv3_3--------------------
layer {
  name: "conv3x_3_1"
  type: "Convolution"
  bottom: "conv3x_2_sum"
  top: "conv3x_3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_3_1"
  type: "ReLU"
  bottom: "conv3x_3_1"
  top: "conv3x_3_1"
}
layer {
  name: "conv3x_3_2"
  type: "Convolution"
  bottom: "conv3x_3_1"
  top: "conv3x_3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_3_2"
  type: "ReLU"
  bottom: "conv3x_3_2"
  top: "conv3x_3_2"
}
layer {
  name: "conv3x_3_3"
  type: "Convolution"
  bottom: "conv3x_3_2"
  top: "conv3x_3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv3x_3_sum"
type:  "Eltwise"
bottom:"conv3x_2_sum"
bottom:"conv3x_3_3"
top:"conv3x_3_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu3x_3_sum"
  type: "ReLU"
  bottom: "conv3x_3_sum"
  top: "conv3x_3_sum"
  }

 # ----conv_4x_-----------------------------------------------

 layer {
  name: "conv4x_top"
  type: "Convolution"
  bottom: "conv3x_3_sum"
  top: "conv4x_top"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	stride :2
	stride :2
	stride :1
	pad :1
	pad :1
	pad :0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
 #------------ block layers conv4_1--------------------
layer {
  name: "conv4x_1_1"
  type: "Convolution"
  bottom: "conv4x_top"
  top: "conv4x_1_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_1_1"
  type: "ReLU"
  bottom: "conv4x_1_1"
  top: "conv4x_1_1"
}
layer {
  name: "conv4x_1_2"
  type: "Convolution"
  bottom: "conv4x_1_1"
  top: "conv4x_1_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_1_2"
  type: "ReLU"
  bottom: "conv4x_1_2"
  top: "conv4x_1_2"
}
layer {
  name: "conv4x_1_3"
  type: "Convolution"
  bottom: "conv4x_1_2"
  top: "conv4x_1_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_1_sum"
type:  "Eltwise"
bottom:"conv4x_top"
bottom:"conv4x_1_3"
top:"conv4x_1_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_1_sum"
  type: "ReLU"
  bottom: "conv4x_1_sum"
  top: "conv4x_1_sum"
  }
#------------ block layers conv4_2--------------------


layer {
  name: "conv4x_2_1"
  type: "Convolution"
  bottom: "conv4x_1_sum"
  top: "conv4x_2_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_2_1"
  type: "ReLU"
  bottom: "conv4x_2_1"
  top: "conv4x_2_1"
}
layer {
  name: "conv4x_2_2"
  type: "Convolution"
  bottom: "conv4x_2_1"
  top: "conv4x_2_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_2_2"
  type: "ReLU"
  bottom: "conv4x_2_2"
  top: "conv4x_2_2"
}
layer {
  name: "conv4x_2_3"
  type: "Convolution"
  bottom: "conv4x_2_2"
  top: "conv4x_2_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_2_sum"
type:  "Eltwise"
bottom:"conv4x_1_sum"
bottom:"conv4x_2_3"
top:"conv4x_2_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_2_sum"
  type: "ReLU"
  bottom: "conv4x_2_sum"
  top: "conv4x_2_sum"
  }

#------------ block layers conv4_3--------------------
layer {
  name: "conv4x_3_1"
  type: "Convolution"
  bottom: "conv4x_2_sum"
  top: "conv4x_3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_3_1"
  type: "ReLU"
  bottom: "conv4x_3_1"
  top: "conv4x_3_1"
}
layer {
  name: "conv4x_3_2"
  type: "Convolution"
  bottom: "conv4x_3_1"
  top: "conv4x_3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_3_2"
  type: "ReLU"
  bottom: "conv4x_3_2"
  top: "conv4x_3_2"
}
layer {
  name: "conv4x_3_3"
  type: "Convolution"
  bottom: "conv4x_3_2"
  top: "conv4x_3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_3_sum"
type:  "Eltwise"
bottom:"conv4x_2_sum"
bottom:"conv4x_3_3"
top:"conv4x_3_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_3_sum"
  type: "ReLU"
  bottom: "conv4x_3_sum"
  top: "conv4x_3_sum"
  }
  # --------------block layers_4_4_-------------------------
  layer {
  name: "conv4x_4_1"
  type: "Convolution"
  bottom: "conv4x_3_sum"
  top: "conv4x_4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_4_1"
  type: "ReLU"
  bottom: "conv4x_4_1"
  top: "conv4x_4_1"
}
layer {
  name: "conv4x_4_2"
  type: "Convolution"
  bottom: "conv4x_4_1"
  top: "conv4x_4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_4_2"
  type: "ReLU"
  bottom: "conv4x_4_2"
  top: "conv4x_4_2"
}
layer {
  name: "conv4x_4_3"
  type: "Convolution"
  bottom: "conv4x_4_2"
  top: "conv4x_4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_4_sum"
type:  "Eltwise"
bottom:"conv4x_3_sum"
bottom:"conv4x_4_3"
top:"conv4x_4_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_4_sum"
  type: "ReLU"
  bottom: "conv4x_4_sum"
  top: "conv4x_4_sum"
  }

 #----------block layers 4x_5-------------------------------
 layer {
  name: "conv4x_5_1"
  type: "Convolution"
  bottom: "conv4x_4_sum"
  top: "conv4x_5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_5_1"
  type: "ReLU"
  bottom: "conv4x_5_1"
  top: "conv4x_5_1"
}
layer {
  name: "conv4x_5_2"
  type: "Convolution"
  bottom: "conv4x_5_1"
  top: "conv4x_5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_5_2"
  type: "ReLU"
  bottom: "conv4x_5_2"
  top: "conv4x_5_2"
}
layer {
  name: "conv4x_5_3"
  type: "Convolution"
  bottom: "conv4x_5_2"
  top: "conv4x_5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_5_sum"
type:  "Eltwise"
bottom:"conv4x_4_sum"
bottom:"conv4x_5_3"
top:"conv4x_5_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_5_sum"
  type: "ReLU"
  bottom: "conv4x_5_sum"
  top: "conv4x_5_sum"
  }

 #--------------------------block_layers  4x_6----------------
 layer {
  name: "conv4x_6_1"
  type: "Convolution"
  bottom: "conv4x_5_sum"
  top: "conv4x_6_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_6_1"
  type: "ReLU"
  bottom: "conv4x_6_1"
  top: "conv4x_6_1"
}
layer {
  name: "conv4x_6_2"
  type: "Convolution"
  bottom: "conv4x_6_1"
  top: "conv4x_6_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_6_2"
  type: "ReLU"
  bottom: "conv4x_6_2"
  top: "conv4x_6_2"
}
layer {
  name: "conv4x_6_3"
  type: "Convolution"
  bottom: "conv4x_6_2"
  top: "conv4x_6_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_6_sum"
type:  "Eltwise"
bottom:"conv4x_5_sum"
bottom:"conv4x_6_3"
top:"conv4x_6_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_6_sum"
  type: "ReLU"
  bottom: "conv4x_6_sum"
  top: "conv4x_6_sum"
  }


 #----------------------conv5x----------------------------------------------------------------------------------------------------
 #---------------conv5_top------------------
 layer {
  name: "conv5x_top"
  type: "Convolution"
  bottom: "conv4x_6_sum"
  top: "conv5x_top"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2048
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	stride :2
	stride :2
	stride :1
	pad :1
	pad :1
	pad :0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
 }



 #---------------conv5x_1------------------------------
layer {
  name: "conv5x_1_1"
  type: "Convolution"
  bottom: "conv5x_top"
  top: "conv5x_1_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu5x_1_1"
  type: "ReLU"
  bottom: "conv5x_1_1"
  top: "conv5x_1_1"
}
layer {
  name: "conv5x_1_2"
  type: "Convolution"
  bottom: "conv5x_1_1"
  top: "conv5x_1_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu5x_1_2"
  type: "ReLU"
  bottom: "conv5x_1_2"
  top: "conv5x_1_2"
}
layer {
  name: "conv5x_1_3"
  type: "Convolution"
  bottom: "conv5x_1_2"
  top: "conv5x_1_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2048
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv5x_1_sum"
type:  "Eltwise"
bottom:"conv5x_top"
bottom:"conv5x_1_3"
top:"conv5x_1_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu5x_1_sum"
  type: "ReLU"
  bottom: "conv5x_1_sum"
  top: "conv5x_1_sum"
  }
 #----------------------conv5x_2------------------------------
 layer {
  name: "conv5x_2_1"
  type: "Convolution"
  bottom: "conv5x_1_sum"
  top: "conv5x_2_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu5x_2_1"
  type: "ReLU"
  bottom: "conv5x_2_1"
  top: "conv5x_2_1"
}
layer {
  name: "conv5x_2_2"
  type: "Convolution"
  bottom: "conv5x_2_1"
  top: "conv5x_2_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu5x_2_2"
  type: "ReLU"
  bottom: "conv5x_2_2"
  top: "conv5x_2_2"
}
layer {
  name: "conv5x_2_3"
  type: "Convolution"
  bottom: "conv5x_2_2"
  top: "conv5x_2_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2048
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv5x_2_sum"
type:  "Eltwise"
bottom:"conv5x_1_sum"
bottom:"conv5x_2_3"
top:"conv5x_2_sum"
eltwise_param{
operation: SUM
}
}

layer{
  name: "drop6"
  type: "Dropout"
  bottom: "conv5x_2_sum"
  top: "conv5x_2_sum"
  dropout_param {
    dropout_ratio: 0.85
  }
  }

layer {
  name: "relu5x_2_sum"
  type: "ReLU"
  bottom: "conv5x_2_sum"
  top: "conv5x_2_sum"
  }


layer {
	bottom: "conv5x_2_sum"
	top: "conv5x_2_sum_bn"
	name: "conv5x_2_sum_bn"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
    phase: TRAIN
  }
}

layer {
	bottom: "conv5x_2_sum"
	top: "conv5x_2_sum_bn"
	name: "conv5x_2_sum_bn"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: true
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	param {
		lr_mult: 0
	}
	include {
    phase: TEST
  }
}

 # layer {
  # name: "fc8"
  # type: "Convolution"
  # bottom: "conv5x_2_sum"
  # top: "fc8"
  # param {
    # lr_mult: 1
  # }
  # param {
    # lr_mult: 2
  # }
  # convolution_param {
    # num_output: 128
	# kernel_size: 7
	# kernel_size: 7
	# kernel_size: 1
    # weight_filler {
      # type: "gaussian"
      # std: 0.005
    # }
    # bias_filler {
      # type: "constant"
      # value: 1
    # }
  # }
# }

layer {
  name: "pool_ave"
  type: "Pooling"
  bottom: "conv5x_2_sum_bn"
  top: "fc8"
  pooling_param {
    pool: AVE
    kernel_shape: 7
	kernel_shape: 7
	kernel_shape: 1
    stride_shape: 1
	stride_shape: 1
	stride_shape: 1
  }
}



 #---------------------------deconv---------------------------

 # layer {
  # name: "relufc8"
  # type: "ReLU"
  # bottom: "fc8"
  # top: "fc8"
  # }




layer {
  name: "fc9"
  type: "Convolution"
  bottom: "fc8"
  top: "fc9"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2
	kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc9"
  bottom: "label"
  top: "loss"
  loss_param{
  ignore_label:3
  }

}

layer{
     name: "accuracy"
     type: "Accuracy"
     bottom: "fc9"
     bottom: "label"
	 top: "accuracy"
	 accuracy_param{
	 ignore_label:3
	 }
	 include {
    phase: TEST
   }
}
