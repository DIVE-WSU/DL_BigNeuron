layer {
  name: "data"
  type: "PatchData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  patch_sampler_param{
	   data_patch_shape{
		dim: 224
		dim: 224
		dim: 8
	   }
	   label_patch_shape{
		dim: 1
		dim: 1
		dim: 1
	   }
	   batch_size: 1
	   patches_per_data_batch: 899999
	   #data_source_batch_size: 1

 }
 
label_select_param{
	balance: true
	num_labels: 3
	num_top_label_balance: 2
	reorder_label: false
	class_prob_mapping_file: 'label_class_selection.prototxt'
}
  transform_nd_param{
    mirror: false
    padding: true
    pad_method: ZERO
  }
  data_provider_param{
    # Specify the data source.
    backend: HDF5
    batch_size: 1
    hdf5_file_shuffle: true
    data_source: "hdf5_train_file_list.txt"
  }

}


layer {
  name: "data"
  type: "PatchData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  patch_sampler_param{
	   data_patch_shape{
		dim: 224
		dim: 224
		dim: 8
	   }
	   label_patch_shape{
		dim: 1
		dim: 1
		dim: 1
	   }
	   batch_size: 1
	   patches_per_data_batch: 899999
	   #data_source_batch_size: 1
 }
 
 label_select_param{
			   balance: true
			   num_labels: 3
			   num_top_label_balance: 2
			   reorder_label: false
			   class_prob_mapping_file: 'label_class_selection_valid.prototxt'
		}
  transform_nd_param{
    mirror: false
    padding: true
    pad_method: ZERO
  }
  data_provider_param{
    # Specify the data source.
    backend: HDF5
    batch_size: 2
    hdf5_file_shuffle: true
    data_source: "hdf5_test_file_list.txt"
  }

}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
	kernel_size: 7
	kernel_size: 4
    stride: 2
	pad:3
	pad:3
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape: 3
	kernel_shape: 3
	kernel_shape: 3
    stride_shape: 2
	stride_shape: 2
	stride_shape: 1
  }
}



#------------------------------------------- conv2x-------------------------------------
#---------------con2x_top-------------

layer {
  name: "conv2x_top"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2x_top"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

#---------------------------  block layers conv2_1 ----------------------------

layer {
  name: "conv2x_1_1"
  type: "Convolution"
  bottom: "conv2x_top"
  top: "conv2x_1_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_1_1"
  type: "ReLU"
  bottom: "conv2x_1_1"
  top: "conv2x_1_1"
}
layer {
  name: "conv2x_1_2"
  type: "Convolution"
  bottom: "conv2x_1_1"
  top: "conv2x_1_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_1_2"
  type: "ReLU"
  bottom: "conv2x_1_2"
  
  
  top: "conv2x_1_2"
}

layer {
  name: "conv2x_1_3"
  type: "Convolution"
  bottom: "conv2x_1_2"
  top: "conv2x_1_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv2x_1_sum"
type:  "Eltwise"
bottom:"conv2x_top"
bottom:"conv2x_1_3"
top:"conv2x_1_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu2x_1_sum"
  type: "ReLU"
  bottom: "conv2x_1_sum"
  top: "conv2x_1_sum"
}



#------------ block layers conv2_2--------------------

layer {
  name: "conv2x_2_1"
  type: "Convolution"
  bottom: "conv2x_1_sum"
  top: "conv2x_2_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_2_1"
  type: "ReLU"
  bottom: "conv2x_2_1"
  top: "conv2x_2_1"
}
layer {
  name: "conv2x_2_2"
  type: "Convolution"
  bottom: "conv2x_2_1"
  top: "conv2x_2_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_2_2"
  type: "ReLU"
  bottom: "conv2x_2_2"
  top: "conv2x_2_2"
}
layer {
  name: "conv2x_2_3"
  type: "Convolution"
  bottom: "conv2x_2_2"
  top: "conv2x_2_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv2x_2_sum"
type:  "Eltwise"
bottom:"conv2x_1_sum"
bottom:"conv2x_2_3"
top:"conv2x_2_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu2x_2_sum"
  type: "ReLU"
  bottom: "conv2x_2_sum"
  top: "conv2x_2_sum"
}
#------------ block layers conv2_3--------------------
layer {
  name: "conv2x_3_1"
  type: "Convolution"
  bottom: "conv2x_2_sum"
  top: "conv2x_3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_3_1"
  type: "ReLU"
  bottom: "conv2x_3_1"
  top: "conv2x_3_1"
}
layer {
  name: "conv2x_3_2"
  type: "Convolution"
  bottom: "conv2x_3_1"
  top: "conv2x_3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu2x_3_2"
  type: "ReLU"
  bottom: "conv2x_3_2"
  top: "conv2x_3_2"
}
layer {
  name: "conv2x_3_3"
  type: "Convolution"
  bottom: "conv2x_3_2"
  top: "conv2x_3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv2x_3_sum"
type:  "Eltwise"
bottom:"conv2x_2_sum"
bottom:"conv2x_3_3"
top:"conv2x_3_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu2x_3_sum"
  type: "ReLU"
  bottom: "conv2x_3_sum"
  top: "conv2x_3_sum"
  }
  
#------------ block layers conv2_3-------------------- 


#------------------- conv3_x_-----------------------
layer {
  name: "conv3x_top"
  type: "Convolution"
  bottom: "conv2x_3_sum"
  top: "conv3x_top"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	stride :2
	stride :2
	stride :1
	pad :1
	pad :1
	pad :0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

#------------ block layers conv3_1-------------------- 
layer {
  name: "conv3x_1_1"
  type: "Convolution"
  bottom: "conv3x_top"
  top: "conv3x_1_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_1_1"
  type: "ReLU"
  bottom: "conv3x_1_1"
  top: "conv3x_1_1"
}
layer {
  name: "conv3x_1_2"
  type: "Convolution"
  bottom: "conv3x_1_1"
  top: "conv3x_1_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_1_2"
  type: "ReLU"
  bottom: "conv3x_1_2"
  top: "conv3x_1_2"
}
layer {
  name: "conv3x_1_3"
  type: "Convolution"
  bottom: "conv3x_1_2"
  top: "conv3x_1_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv3x_1_sum"
type:  "Eltwise"
bottom:"conv3x_top"
bottom:"conv3x_1_3"
top:"conv3x_1_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu3x_1_sum"
  type: "ReLU"
  bottom: "conv3x_1_sum"
  top: "conv3x_1_sum"
  }
#------------ block layers conv3_2-------------------- 
 
  
layer {
  name: "conv3x_2_1"
  type: "Convolution"
  bottom: "conv3x_1_sum"
  top: "conv3x_2_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_2_1"
  type: "ReLU"
  bottom: "conv3x_2_1"
  top: "conv3x_2_1"
}
layer {
  name: "conv3x_2_2"
  type: "Convolution"
  bottom: "conv3x_2_1"
  top: "conv3x_2_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_2_2"
  type: "ReLU"
  bottom: "conv3x_2_2"
  top: "conv3x_2_2"
}
layer {
  name: "conv3x_2_3"
  type: "Convolution"
  bottom: "conv3x_2_2"
  top: "conv3x_2_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv3x_2_sum"
type:  "Eltwise"
bottom:"conv3x_1_sum"
bottom:"conv3x_2_3"
top:"conv3x_2_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu3x_2_sum"
  type: "ReLU"
  bottom: "conv3x_2_sum"
  top: "conv3x_2_sum"
  }

#------------ block layers conv3_3-------------------- 
layer {
  name: "conv3x_3_1"
  type: "Convolution"
  bottom: "conv3x_2_sum"
  top: "conv3x_3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_3_1"
  type: "ReLU"
  bottom: "conv3x_3_1"
  top: "conv3x_3_1"
}
layer {
  name: "conv3x_3_2"
  type: "Convolution"
  bottom: "conv3x_3_1"
  top: "conv3x_3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu3x_3_2"
  type: "ReLU"
  bottom: "conv3x_3_2"
  top: "conv3x_3_2"
}
layer {
  name: "conv3x_3_3"
  type: "Convolution"
  bottom: "conv3x_3_2"
  top: "conv3x_3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv3x_3_sum"
type:  "Eltwise"
bottom:"conv3x_2_sum"
bottom:"conv3x_3_3"
top:"conv3x_3_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu3x_3_sum"
  type: "ReLU"
  bottom: "conv3x_3_sum"
  top: "conv3x_3_sum"
  }
 
 # ----conv_4x_-----------------------------------------------
 
 layer {
  name: "conv4x_top"
  type: "Convolution"
  bottom: "conv3x_3_sum"
  top: "conv4x_top"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	stride :2
	stride :2
	stride :1
	pad :1
	pad :1
	pad :0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
 #------------ block layers conv4_1-------------------- 
layer {
  name: "conv4x_1_1"
  type: "Convolution"
  bottom: "conv4x_top"
  top: "conv4x_1_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_1_1"
  type: "ReLU"
  bottom: "conv4x_1_1"
  top: "conv4x_1_1"
}
layer {
  name: "conv4x_1_2"
  type: "Convolution"
  bottom: "conv4x_1_1"
  top: "conv4x_1_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_1_2"
  type: "ReLU"
  bottom: "conv4x_1_2"
  top: "conv4x_1_2"
}
layer {
  name: "conv4x_1_3"
  type: "Convolution"
  bottom: "conv4x_1_2"
  top: "conv4x_1_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_1_sum"
type:  "Eltwise"
bottom:"conv4x_top"
bottom:"conv4x_1_3"
top:"conv4x_1_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_1_sum"
  type: "ReLU"
  bottom: "conv4x_1_sum"
  top: "conv4x_1_sum"
  }
#------------ block layers conv4_2-------------------- 
 
  
layer {
  name: "conv4x_2_1"
  type: "Convolution"
  bottom: "conv4x_1_sum"
  top: "conv4x_2_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_2_1"
  type: "ReLU"
  bottom: "conv4x_2_1"
  top: "conv4x_2_1"
}
layer {
  name: "conv4x_2_2"
  type: "Convolution"
  bottom: "conv4x_2_1"
  top: "conv4x_2_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_2_2"
  type: "ReLU"
  bottom: "conv4x_2_2"
  top: "conv4x_2_2"
}
layer {
  name: "conv4x_2_3"
  type: "Convolution"
  bottom: "conv4x_2_2"
  top: "conv4x_2_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_2_sum"
type:  "Eltwise"
bottom:"conv4x_1_sum"
bottom:"conv4x_2_3"
top:"conv4x_2_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_2_sum"
  type: "ReLU"
  bottom: "conv4x_2_sum"
  top: "conv4x_2_sum"
  }

#------------ block layers conv4_3-------------------- 
layer {
  name: "conv4x_3_1"
  type: "Convolution"
  bottom: "conv4x_2_sum"
  top: "conv4x_3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_3_1"
  type: "ReLU"
  bottom: "conv4x_3_1"
  top: "conv4x_3_1"
}
layer {
  name: "conv4x_3_2"
  type: "Convolution"
  bottom: "conv4x_3_1"
  top: "conv4x_3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_3_2"
  type: "ReLU"
  bottom: "conv4x_3_2"
  top: "conv4x_3_2"
}
layer {
  name: "conv4x_3_3"
  type: "Convolution"
  bottom: "conv4x_3_2"
  top: "conv4x_3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_3_sum"
type:  "Eltwise"
bottom:"conv4x_2_sum"
bottom:"conv4x_3_3"
top:"conv4x_3_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_3_sum"
  type: "ReLU"
  bottom: "conv4x_3_sum"
  top: "conv4x_3_sum"
  }
  # --------------block layers_4_4_-------------------------
  layer {
  name: "conv4x_4_1"
  type: "Convolution"
  bottom: "conv4x_3_sum"
  top: "conv4x_4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_4_1"
  type: "ReLU"
  bottom: "conv4x_4_1"
  top: "conv4x_4_1"
}
layer {
  name: "conv4x_4_2"
  type: "Convolution"
  bottom: "conv4x_4_1"
  top: "conv4x_4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_4_2"
  type: "ReLU"
  bottom: "conv4x_4_2"
  top: "conv4x_4_2"
}
layer {
  name: "conv4x_4_3"
  type: "Convolution"
  bottom: "conv4x_4_2"
  top: "conv4x_4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_4_sum"
type:  "Eltwise"
bottom:"conv4x_3_sum"
bottom:"conv4x_4_3"
top:"conv4x_4_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_4_sum"
  type: "ReLU"
  bottom: "conv4x_4_sum"
  top: "conv4x_4_sum"
  }
  
 #----------block layers 4x_5-------------------------------
 layer {
  name: "conv4x_5_1"
  type: "Convolution"
  bottom: "conv4x_4_sum"
  top: "conv4x_5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_5_1"
  type: "ReLU"
  bottom: "conv4x_5_1"
  top: "conv4x_5_1"
}
layer {
  name: "conv4x_5_2"
  type: "Convolution"
  bottom: "conv4x_5_1"
  top: "conv4x_5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_5_2"
  type: "ReLU"
  bottom: "conv4x_5_2"
  top: "conv4x_5_2"
}
layer {
  name: "conv4x_5_3"
  type: "Convolution"
  bottom: "conv4x_5_2"
  top: "conv4x_5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_5_sum"
type:  "Eltwise"
bottom:"conv4x_4_sum"
bottom:"conv4x_5_3"
top:"conv4x_5_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_5_sum"
  type: "ReLU"
  bottom: "conv4x_5_sum"
  top: "conv4x_5_sum"
  }
  
 #--------------------------block_layers  4x_6---------------- 
 layer {
  name: "conv4x_6_1"
  type: "Convolution"
  bottom: "conv4x_5_sum"
  top: "conv4x_6_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_6_1"
  type: "ReLU"
  bottom: "conv4x_6_1"
  top: "conv4x_6_1"
}
layer {
  name: "conv4x_6_2"
  type: "Convolution"
  bottom: "conv4x_6_1"
  top: "conv4x_6_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu4x_6_2"
  type: "ReLU"
  bottom: "conv4x_6_2"
  top: "conv4x_6_2"
}
layer {
  name: "conv4x_6_3"
  type: "Convolution"
  bottom: "conv4x_6_2"
  top: "conv4x_6_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv4x_6_sum"
type:  "Eltwise"
bottom:"conv4x_5_sum"
bottom:"conv4x_6_3"
top:"conv4x_6_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu4x_6_sum"
  type: "ReLU"
  bottom: "conv4x_6_sum"
  top: "conv4x_6_sum"
  }
  
  
 #----------------------conv5x----------------------------------------------------------------------------------------------------
 #---------------conv5_top------------------
 layer {
  name: "conv5x_top"
  type: "Convolution"
  bottom: "conv4x_6_sum"
  top: "conv5x_top"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2048
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	stride :2
	stride :2
	stride :1
	pad :1
	pad :1
	pad :0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
 }
  
  
  
 #---------------conv5x_1------------------------------
layer {
  name: "conv5x_1_1"
  type: "Convolution"
  bottom: "conv5x_top"
  top: "conv5x_1_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu5x_1_1"
  type: "ReLU"
  bottom: "conv5x_1_1"
  top: "conv5x_1_1"
}
layer {
  name: "conv5x_1_2"
  type: "Convolution"
  bottom: "conv5x_1_1"
  top: "conv5x_1_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu5x_1_2"
  type: "ReLU"
  bottom: "conv5x_1_2"
  top: "conv5x_1_2"
}
layer {
  name: "conv5x_1_3"
  type: "Convolution"
  bottom: "conv5x_1_2"
  top: "conv5x_1_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2048
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv5x_1_sum"
type:  "Eltwise"
bottom:"conv5x_top"
bottom:"conv5x_1_3"
top:"conv5x_1_sum"
eltwise_param{
operation: SUM
}
}

layer {
  name: "relu5x_1_sum"
  type: "ReLU"
  bottom: "conv5x_1_sum"
  top: "conv5x_1_sum"
  }
 #----------------------conv5x_2------------------------------
 layer {
  name: "conv5x_2_1"
  type: "Convolution"
  bottom: "conv5x_1_sum"
  top: "conv5x_2_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu5x_2_1"
  type: "ReLU"
  bottom: "conv5x_2_1"
  top: "conv5x_2_1"
}
layer {
  name: "conv5x_2_2"
  type: "Convolution"
  bottom: "conv5x_2_1"
  top: "conv5x_2_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
	kernel_size: 3
	kernel_size: 1
	pad:1
	pad:1
	pad:0
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "relu5x_2_2"
  type: "ReLU"
  bottom: "conv5x_2_2"
  top: "conv5x_2_2"
}
layer {
  name: "conv5x_2_3"
  type: "Convolution"
  bottom: "conv5x_2_2"
  top: "conv5x_2_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2048
	kernel_size: 1
    weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
name: "conv5x_2_sum"
type:  "Eltwise"
bottom:"conv5x_1_sum"
bottom:"conv5x_2_3"
top:"conv5x_2_sum"
eltwise_param{
operation: SUM
}
}

layer{
  name: "drop6"
  type: "Dropout"
  bottom: "conv5x_2_sum"
  top: "conv5x_2_sum"
  dropout_param {
    dropout_ratio: 0.5
  }
  }

layer {
  name: "relu5x_2_sum"
  type: "ReLU"
  bottom: "conv5x_2_sum"
  top: "conv5x_2_sum"
  }
 
 
 #---------------------------deconv--------------------------- 

layer{
 name: "deconv1_1x"
  type: "Convolution"
   bottom: "conv2x_3_sum"
   top: "deconv1_1x"
  param {
     lr_mult: 20
  }
  param {
     lr_mult: 10
  }
  convolution_param {
     num_output: 2
     kernel_size: 1
	 kernel_size: 1
	 kernel_size: 1
	 stride: 1
	 stride: 1
	 stride: 1
	 pad:0
	  pad:0
	 pad:0
   # weight_filler {
      # type: "bilinear"
    # }
	 weight_filler {
       type: "gaussian"
	   std: 0.01
    }
     bias_filler {
       type: "constant"
       value: 0
    }
   }
 }
# layer{
  # name: "drop1_1x"
  # type: "Dropout"
  # bottom: "deconv1_1x"
  # top: "deconv1_1x"
  # dropout_param {
    # dropout_ratio: 0.5
  # }
  # }


layer{
name: "deconv2_1x"
  type: "Convolution"
  bottom: "conv3x_3_sum"
  top: "deconv2_1x"
 param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
	kernel_size: 1
	kernel_size: 1
	stride: 1
	stride: 1
	stride: 1
   weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer{
  name: "drop2_1x"
  type: "Dropout"
  bottom: "deconv2_1x"
  top: "deconv2_1x"
  dropout_param {
    dropout_ratio: 0.5
  }
  }

layer{
name: "deconv3_1x"
  type: "Convolution"
  bottom: "conv4x_6_sum"
  top: "deconv3_1x"
 param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
	kernel_size: 1
	kernel_size: 1
	stride: 1
	stride: 1
	stride: 1
   weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer{
  name: "drop3_1x"
  type: "Dropout"
  bottom: "deconv3_1x"
  top: "deconv3_1x"
  dropout_param {
    dropout_ratio: 0.5
  }
  }

layer{
name: "deconv4_1x"
  type: "Convolution"
  bottom: "conv5x_2_sum"
  top: "deconv4_1x"
 param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
	kernel_size: 1
	kernel_size: 1
	stride: 1
	stride: 1
	stride: 1
   weight_filler {
      type: "gaussian"
	  std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer{
  name: "drop4_1x"
  type: "Dropout"
  bottom: "deconv4_1x"
  top: "deconv4_1x"
  dropout_param {
    dropout_ratio: 0.5
  }
  }




layer{
name: "deconv4_2x"
  type: "Deconvolution"
  bottom: "deconv4_1x"
  top: "deconv4_2x"
 param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  convolution_param {
    num_output: 2
    kernel_size: 4
	kernel_size: 4
	kernel_size: 1
	stride: 2
	stride: 2
	stride: 1
	pad:1
	pad:1
	pad:0
   weight_filler {
      type: "bilinear"
    }
  }
}


layer{
name: "deconv_sum_43"
type:  "Eltwise"
bottom:"deconv4_2x"
bottom:"deconv3_1x"
top:"upsample43"
eltwise_param{
operation: SUM
}
}



layer{
name: "upsample43_2x"
  type: "Deconvolution"
  bottom: "upsample43"
  top: "upsample43_2x"
 param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  convolution_param {
    num_output: 2
    kernel_size: 4
	kernel_size: 4
	kernel_size: 1
	stride: 2
	stride: 2
	stride: 1
	pad:1
	pad:1
	pad:0
   weight_filler {
      type: "bilinear"
    }
  }
}


layer{
name: "deconv_sum_432"
type:  "Eltwise"
bottom:"upsample43_2x"
bottom:"deconv2_1x"
top:"upsample432"
eltwise_param{
operation: SUM
}
}


layer{
name: "upsample432_2x"
  type: "Deconvolution"
  bottom: "upsample432"
  top: "upsample432_2x"
 param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  convolution_param {
    num_output: 2
    kernel_size: 4
	kernel_size: 4
	kernel_size: 1
	stride: 2
	stride: 2
	stride: 1
	pad:1
	pad:1
	pad:0
   weight_filler {
      type: "bilinear"
    }
  }
}

layer{
 name: "deconv_sum_4321"
 type:  "Eltwise"
 bottom:"upsample432_2x"
 bottom:"deconv1_1x"
 top:"upsample4321"
 eltwise_param{
 operation: SUM
 }
 }


layer{
name: "upsample4321_2x"
  type: "Deconvolution"
  bottom: "upsample4321"
  top: "upsample4321_2x"
 param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  convolution_param {
    num_output: 2
    kernel_size: 8
	kernel_size: 8
	kernel_size: 1
	stride: 4
	stride: 4
	stride: 1
	pad:2
	pad:2
	pad:0
   weight_filler {
      type: "bilinear"
    }
  }
}





# layer{
# name: "deconv_sum"
# type:  "Eltwise"
# bottom:"deconv4_2x"
# bottom:"deconv3"
# bottom:"deconv3"
# bottom:"deconv4"
# top:"upsample"
# eltwise_param{
# operation: SUM
# }
# }



# layer{
# name: "deconv_sum"
# type:  "Eltwise"
# bottom:"deconv1"
# bottom:"deconv2"
# bottom:"deconv3"
# bottom:"deconv4"
# top:"upsample"
# eltwise_param{
# operation: SUM
# }
# }






layer {
  name: "fc"
  type: "Convolution"
  bottom: "upsample4321_2x"
  top: "fc"
  param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  convolution_param {
    num_output: 2
	kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc"
  bottom: "label"
  top: "loss"
  loss_param{
  ignore_label:3
  }
label_select_param{
	balance: true
	num_labels: 3
	num_top_label_balance: 2
	reorder_label: false
	class_prob_mapping_file: 'label_weight.prototxt'
	}
}

layer{
     name: "accuracy"
     type: "Accuracy"
     bottom: "fc"
     bottom: "label" 
	 top: "accuracy"
	 accuracy_param{
	 ignore_label:3
	 }
	 include {
    phase: TEST
   }
}
